AI Security Lens

Advanced Security Platform for AI-Assisted Development

Team: SRE Assist (Krishna Kallakuri, Sunith Neelanath, Ravi Julapalli, Ramsai Nelluri)
Hackathon: Hack the Vibe 2025 - Vibe Coding Challenge


Overview
AI Security Lens is a comprehensive security platform that provides real-time threat detection and automated vulnerability mitigation for AI-assisted development workflows. The system addresses critical security challenges in AI-powered software development, including prompt injection attacks, code vulnerability generation, and autonomous agent security oversight.
Key Innovation
Iterative Security Refinement - Our unique approach doesn't just detect vulnerabilities; it automatically engages with AI models to progressively improve code security through guided refinement cycles, reducing risk scores from 90% to 15% automatically.
Problem Statement
As organizations adopt AI development tools, new security challenges emerge:

Prompt Injection Attacks: Malicious users manipulate AI behavior to bypass safety measures
Vulnerable Code Generation: AI models produce code with SQL injection, command injection, and other critical vulnerabilities
Autonomous Agent Risks: AI agents operate without security oversight in production environments
Data Poisoning: Attackers inject malicious patterns into AI responses

Solution Architecture
Multi-Layer Security Detection

Enhanced Prompt Analysis: Pattern-based detection for injection attempts and malicious inputs
Code Vulnerability Scanning: AST analysis and ML-based pattern recognition for security flaws
Behavioral Monitoring: Anomaly detection for unusual user interaction patterns
Iterative Refinement: Automatic security improvement through guided AI interaction

Supported AI Models

OpenAI GPT-4 and GPT-3.5-Turbo
Anthropic Claude (all versions)
Google Gemini Pro

Features
ğŸ›¡ï¸ Real-Time Security Analysis

Comprehensive vulnerability detection (SQL injection, command injection, XSS, etc.)
Prompt injection attack prevention
Data poisoning attempt identification

ğŸ”„ Iterative Security Refinement

Automatic code improvement through AI collaboration
Progressive vulnerability elimination
Maintains functionality while enhancing security

ğŸ“Š Security Analytics Dashboard

Risk scoring and trend analysis
Comprehensive audit trails
Performance monitoring and metrics

ğŸ”— Enterprise Integration

Multi-LLM support with unified security policies
Model Context Protocol (MCP) deployment ready
API-first architecture for easy integration

Quick Start
Prerequisites

Python 3.9 or higher
API keys for supported LLM providers
8GB RAM (recommended for optimal performance)

Installation
bash# Clone the repository
git clone https://github.com/your-org/ai-security-lens.git
cd ai-security-lens

# Install dependencies
pip install -r requirements.txt

# Set up environment variables
cp .env.example .env
# Edit .env with your API keys

# Initialize database
python -m database.db_manager

# Run the application
streamlit run main.py
Environment Configuration
Create a .env file with your API keys:
envOPENAI_API_KEY=your_openai_key_here
ANTHROPIC_API_KEY=your_claude_key_here
GEMINI_API_KEY=your_gemini_key_here

# Security Configuration
INJECTION_THRESHOLD=0.7
SQL_INJECTION_THRESHOLD=0.6
AI_SAFETY_THRESHOLD=0.8
Usage Examples
Basic Security Analysis
pythonfrom security.enhanced_prompt_analyzer import PromptAnalyzer

analyzer = PromptAnalyzer(db_manager)
results = analyzer.analyze_prompt_comprehensive(
    "Create a user login function with database authentication"
)

print(f"Risk Score: {results['risk_score']}")
print(f"Vulnerabilities: {len(results['code_vulnerabilities'])}")
Iterative Security Improvement
The system automatically detects and improves vulnerable code:
Before (Risk: 90%):
pythondef authenticate(username, password):
    query = f"SELECT * FROM users WHERE name = '{username}' AND pass = '{password}'"
    return db.execute(query)
After Refinement (Risk: 15%):
pythondef authenticate(username, password):
    query = "SELECT * FROM users WHERE name = ? AND pass = ?"
    return db.execute(query, (username, password))
Project Structure
ai-security-lens/
â”œâ”€â”€ main.py                    # Main Streamlit application
â”œâ”€â”€ config/
â”‚   â””â”€â”€ settings.py           # Configuration management
â”œâ”€â”€ database/
â”‚   â”œâ”€â”€ db_manager.py         # Database operations
â”‚   â””â”€â”€ models.py             # SQLAlchemy models
â”œâ”€â”€ security/
â”‚   â”œâ”€â”€ enhanced_prompt_analyzer.py    # Core security analysis
â”‚   â”œâ”€â”€ code_analyzer.py               # Code vulnerability detection
â”‚   â”œâ”€â”€ ml_analyzer.py                 # ML-based threat detection
â”‚   â”œâ”€â”€ behavioral_analyzer.py         # User behavior analysis
â”‚   â””â”€â”€ performance_monitor.py         # System monitoring
â”œâ”€â”€ llm_clients/
â”‚   â”œâ”€â”€ openai_client.py      # OpenAI integration
â”‚   â”œâ”€â”€ claude_client.py      # Anthropic Claude integration
â”‚   â””â”€â”€ gemini_client.py      # Google Gemini integration
â””â”€â”€ requirements.txt
Security Features
Vulnerability Detection

SQL Injection: Pattern matching and parameterized query validation
Command Injection: System call analysis and shell execution detection
Path Traversal: File access pattern validation
Deserialization Attacks: Unsafe pickle/marshal usage detection
Weak Cryptography: Deprecated algorithm identification

Advanced Protection

Prompt Injection Defense: Multi-pattern detection with semantic analysis
Data Poisoning Prevention: Malicious payload identification
Behavioral Anomaly Detection: User pattern analysis for threat identification

Development
Running Tests
bash# Run security analysis tests
python -m pytest tests/security/

# Test LLM integrations
python -m pytest tests/llm_clients/

# Full test suite
python -m pytest
Development Setup
bash# Install development dependencies
pip install -r requirements-dev.txt

# Pre-commit hooks
pre-commit install

# Code formatting
black .
isort .
Deployment
Production Deployment
bash# Using Docker
docker build -t ai-security-lens .
docker run -p 8501:8501 ai-security-lens

# Using environment variables for production
export STREAMLIT_SERVER_PORT=8501
export STREAMLIT_SERVER_ADDRESS=0.0.0.0
streamlit run main.py
Model Context Protocol Integration
Deploy as MCP service for enterprise-wide security analysis:
json{
  "name": "ai-security-lens",
  "description": "Security analysis for AI-generated content",
  "version": "1.0.0",
  "endpoints": {
    "analyze": "/api/v1/analyze",
    "refine": "/api/v1/refine"
  }
}
Performance Metrics

Detection Accuracy: 94.2% vulnerability identification rate
Response Time: <3 seconds for complete analysis and refinement
Risk Reduction: Average 78% improvement through iterative refinement
False Positive Rate: <5% for security threat detection

Use Cases
For Development Teams

Real-time security analysis during AI-assisted coding
Automated code review and vulnerability remediation
Security training through detailed vulnerability explanations

For Enterprise Organizations

Centralized security governance for AI development tools
Compliance reporting and audit trail generation
Risk assessment and management for AI-generated code

For Autonomous AI Agents

Security oversight for agent-generated code modifications
Threat detection in agent decision-making processes
Automated security validation for agent outputs
